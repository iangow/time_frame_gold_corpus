{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d9956a",
   "metadata": {},
   "source": [
    "# Classification performance of the keyword search algorithm\n",
    "\n",
    "The data and code here produces the in-sample and out-of-sample classification performance statistics.\n",
    "\n",
    "I use keyword search to find forward-looking sentences. The keyword list for forward-looking is uploaded [here](https://github.com/yiyangw2/time_frame_gold_corpus/blob/main/fls_terms2.txt). Besides, I determine that if a sentence contains words of years for the coming ten years, it is also forward-looking. The word list is adapted from [previous studies](https://pubsonline.informs.org/doi/abs/10.1287/mnsc.2014.1921).\n",
    "\n",
    "Among the forward-looking statements, I use a time frame keyword list to identify those with time frames. The keyword list for time frames is uploaded [here](https://github.com/yiyangw2/time_frame_gold_corpus/blob/main/qt_terms2.txt).The time frame keyword list is adapted from  [previous studies](https://link.springer.com/article/10.1007/s11142-015-9329-8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a00b876b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>last_update</th>\n",
       "      <th>section</th>\n",
       "      <th>context</th>\n",
       "      <th>speaker_number</th>\n",
       "      <th>future_year</th>\n",
       "      <th>speaker_text</th>\n",
       "      <th>fl</th>\n",
       "      <th>qt</th>\n",
       "      <th>fl_qt</th>\n",
       "      <th>fl_cal</th>\n",
       "      <th>qt_cal</th>\n",
       "      <th>fl_qt_cal</th>\n",
       "      <th>training sample</th>\n",
       "      <th>test sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12614899_T</td>\n",
       "      <td>2019-08-01 19:19:18+10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>qa</td>\n",
       "      <td>23</td>\n",
       "      <td>2019</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12614899_T</td>\n",
       "      <td>2019-08-01 19:19:18+10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>qa</td>\n",
       "      <td>23</td>\n",
       "      <td>2019</td>\n",
       "      <td>And lastly from me, can you kind of give us a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12614899_T</td>\n",
       "      <td>2019-08-01 19:19:18+10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>qa</td>\n",
       "      <td>23</td>\n",
       "      <td>2019</td>\n",
       "      <td>What's the share of wallet for Knoll products?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>702568_T</td>\n",
       "      <td>2003-01-30 16:25:51+11:00</td>\n",
       "      <td>1</td>\n",
       "      <td>qa</td>\n",
       "      <td>109</td>\n",
       "      <td>2003</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>702568_T</td>\n",
       "      <td>2003-01-30 16:25:51+11:00</td>\n",
       "      <td>1</td>\n",
       "      <td>qa</td>\n",
       "      <td>109</td>\n",
       "      <td>2003</td>\n",
       "      <td>So I don't think anybody said much more.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>2723598_T</td>\n",
       "      <td>2010-02-17 13:53:38+11:00</td>\n",
       "      <td>1</td>\n",
       "      <td>pres</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>With that, let's open the call to your questions.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>2723598_T</td>\n",
       "      <td>2010-02-17 13:53:38+11:00</td>\n",
       "      <td>1</td>\n",
       "      <td>pres</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>Yvette, please review the Q&amp;A procedure.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>739440_T</td>\n",
       "      <td>2003-05-07 12:37:12+10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>qa</td>\n",
       "      <td>154</td>\n",
       "      <td>2003</td>\n",
       "      <td>This is a follow up question from Chris Joseph...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>739440_T</td>\n",
       "      <td>2003-05-07 12:37:12+10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>qa</td>\n",
       "      <td>154</td>\n",
       "      <td>2003</td>\n",
       "      <td>from [inaudible].</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>739440_T</td>\n",
       "      <td>2003-05-07 12:37:12+10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>qa</td>\n",
       "      <td>154</td>\n",
       "      <td>2003</td>\n",
       "      <td>Please go ahead.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1288 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_name                last_update  section context  speaker_number  \\\n",
       "0     12614899_T  2019-08-01 19:19:18+10:00        1      qa              23   \n",
       "1     12614899_T  2019-08-01 19:19:18+10:00        1      qa              23   \n",
       "2     12614899_T  2019-08-01 19:19:18+10:00        1      qa              23   \n",
       "3       702568_T  2003-01-30 16:25:51+11:00        1      qa             109   \n",
       "4       702568_T  2003-01-30 16:25:51+11:00        1      qa             109   \n",
       "...          ...                        ...      ...     ...             ...   \n",
       "1283   2723598_T  2010-02-17 13:53:38+11:00        1    pres               5   \n",
       "1284   2723598_T  2010-02-17 13:53:38+11:00        1    pres               5   \n",
       "1285    739440_T  2003-05-07 12:37:12+10:00        1      qa             154   \n",
       "1286    739440_T  2003-05-07 12:37:12+10:00        1      qa             154   \n",
       "1287    739440_T  2003-05-07 12:37:12+10:00        1      qa             154   \n",
       "\n",
       "      future_year                                       speaker_text  fl  qt  \\\n",
       "0            2019                                              Okay.   0   0   \n",
       "1            2019  And lastly from me, can you kind of give us a ...   0   0   \n",
       "2            2019     What's the share of wallet for Knoll products?   0   0   \n",
       "3            2003                                              Okay.   0   0   \n",
       "4            2003           So I don't think anybody said much more.   0   0   \n",
       "...           ...                                                ...  ..  ..   \n",
       "1283         2010  With that, let's open the call to your questions.   0   0   \n",
       "1284         2010           Yvette, please review the Q&A procedure.   0   0   \n",
       "1285         2003  This is a follow up question from Chris Joseph...   0   0   \n",
       "1286         2003                                  from [inaudible].   0   0   \n",
       "1287         2003                                   Please go ahead.   0   0   \n",
       "\n",
       "      fl_qt  fl_cal  qt_cal  fl_qt_cal  training sample  test sample  \n",
       "0         0       0       0          0                0            0  \n",
       "1         0       0       0          0                1            0  \n",
       "2         0       0       0          0                1            0  \n",
       "3         0       0       0          0                1            0  \n",
       "4         0       0       0          0                1            0  \n",
       "...     ...     ...     ...        ...              ...          ...  \n",
       "1283      0       0       0          0                0            1  \n",
       "1284      0       0       0          0                1            0  \n",
       "1285      0       0       0          0                1            0  \n",
       "1286      0       0       0          0                1            0  \n",
       "1287      0       0       0          0                0            1  \n",
       "\n",
       "[1288 rows x 15 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "gold_standard = pd.read_excel(\"Gold Standard Corpus.xlsx\")\n",
    "gold_standard[['file_name', 'last_update', 'section', 'context', 'speaker_number', 'future_year','speaker_text', 'fl', 'qt', 'fl_qt', 'fl_cal',\n",
    "       'qt_cal', 'fl_qt_cal', 'training sample', 'test sample']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae3f84",
   "metadata": {},
   "source": [
    "The underlying text associated with the gold standard is found in [`Gold Standard Corpus.xlsx`](https://github.com/yiyangw2/time_frame_gold_corpus/blob/main/Gold%20Standard%20Corpus.xlsx). It is composed of 200 randomly picked up paragraphs of the management (1288 sentences). As you can see, each sentence has identifiers for where it comes from. And values for `fl_cal`,`qt_cal` and `fl_qt_cal`, reflecting whether the algorithm determines that whether the sentence is forward-looking, whether it contains time frames and whether it is a forward-looking statement with time frames. Similarly, each observation has values for `fl`,`qt` and `fl_qt`, which is whether I manually determine that whether the sentence is forward-looking, whether it contains time frames and whether it is a forward-looking statement with time frames. The underlying earnings calls' scripts are from the Melbourne Centre for Corporate Governance and Regulation (MCCGR) database. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30beaca8",
   "metadata": {},
   "source": [
    "The following function applies the identification functions to each sentence and shows how `fl_cal`, `qt_cal` and `fl_qt_cal` in `gold_standard` are produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8c2de133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "\n",
    "def word_count(sent):\n",
    "    words = word_tokenize(sent)\n",
    "    words_clean = [t for t in words if not _is_punctuation(t)]\n",
    "    # print(words_clean)\n",
    "    return len(words_clean)\n",
    "\n",
    "punctuation_regex = r'[!\\\"#$%&\\'\\\\()*+,-./:;<=>?@[\\]^_`{|}~â€™]'\n",
    "\n",
    "def _is_punctuation(token):\n",
    "    match = re.match(r'^' + punctuation_regex + r'$', token)\n",
    "    return match is not None\n",
    "\n",
    "def clean_sent(sent):\n",
    "    return re.sub(punctuation_regex, \"\", sent)\n",
    "\n",
    "def text_word_count(text):\n",
    "    sents = sent_tokenize(text)\n",
    "    clean_sents = [clean_sent(sent) for sent in sents]\n",
    "    return sum([word_count(sent) for sent in clean_sents])\n",
    "\n",
    "def create_regex_list(terms_file:str):\n",
    "    \"\"\"Creates a list of regex expressions of\n",
    "    short term orientation\"\"\"\n",
    "\n",
    "    # opens the specified dict_file in \"r\" (read) mode\n",
    "    with open(terms_file,\"r\") as file:\n",
    "        # reads the content of the file line-by-line\n",
    "        # and creates a list of terms\n",
    "        terms = file.read().splitlines()\n",
    "\n",
    "    # creates a list of regex expressions by adding\n",
    "    # word boundary (\\b) anchors to the beginning and\n",
    "    # the ending of each FLS term\n",
    "    terms_regex = [re.compile(r'\\b' + term + r'\\b') for term in terms]\n",
    "    return terms_regex\n",
    "\n",
    "\n",
    "def create_fls_regex_list(fls_terms_file:str):\n",
    "    \"\"\"Creates a list of regex expressions of\n",
    "    FLS terms\"\"\"\n",
    "\n",
    "    # opens the specified dict_file in \"r\" (read) mode\n",
    "    with open(fls_terms_file,\"r\") as file:\n",
    "        # reads the content of the file line-by-line\n",
    "        # and creates a list of FLS terms\n",
    "        fls_terms = file.read().splitlines()\n",
    "\n",
    "    # creates a list of FLS regex expressions by adding\n",
    "    # word boundary (\\b) anchors to the beginning and\n",
    "    # the ending of each FLS term\n",
    "    fls_terms_regex = [re.compile(r'\\b' + term + r'\\b') for term in fls_terms]\n",
    "    return fls_terms_regex\n",
    "\n",
    "fls_terms_file = r\"fls_terms2.txt\"\n",
    "\n",
    "fls_terms_regex = create_fls_regex_list(fls_terms_file)\n",
    "\n",
    "def is_forward_looking(sentence:str, fls_terms_regex):\n",
    "    \"\"\"Returns whether sentence is forward-looking.\"\"\"\n",
    "    for fls_term in fls_terms_regex:\n",
    "        if fls_term.search(sentence):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "qt_terms_file = r\"qt_terms2.txt\"\n",
    "\n",
    "qt_terms_regex = create_regex_list(qt_terms_file)\n",
    "# print(lt_terms_regex[0:3])\n",
    "\n",
    "def count_term(text:str, qt_terms_regex_with_future_years):\n",
    "    \"\"\"Returns the number of long-term oriented.\"\"\"\n",
    "    text = text.lower()\n",
    "    qt_count = 0\n",
    "    for qt_term in qt_terms_regex_with_future_years:\n",
    "      qt_count = qt_count + len(re.findall(qt_term, text))\n",
    "    return qt_count\n",
    "\n",
    "def is_term(text:str, qt_terms_regex):\n",
    "  text = text.lower() \n",
    "  if count_term(text, qt_terms_regex) > 0:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_future_year(text:str, future_year_terms):\n",
    "  text = text.lower()\n",
    "  if count_term(text, future_year_terms) > 0:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6db6d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disclosure_horizon(the_text, fls_key_list=fls_terms_regex, qt_key_list=qt_terms_regex, future_year=2023): \n",
    "  fl_dict = {}\n",
    "  sentences = nltk.tokenize.sent_tokenize(the_text)\n",
    "  nfl_sent = 0\n",
    "  nfl_qt_sent = 0\n",
    "  nfl_qt_sent_keys = 0 \n",
    "  nfl_qt_sent_year = 0\n",
    "  nfl_qt_sent_both = 0\n",
    "  nfl_nqt_sent = 0 \n",
    "  fl_sent = 0\n",
    "  fl_qt_sent = 0\n",
    "  fl_qt_sent_keys = 0 \n",
    "  fl_qt_sent_year = 0\n",
    "  fl_qt_sent_both = 0\n",
    "  fl_nqt_sent = 0 \n",
    "  \n",
    "  future_year = int(future_year)  \n",
    "  future_year_terms=[re.compile(r\"[^$,]\\b\" + str(y) + r\"\\b(?!(%|,\\d|.\\d))\") for y in range(future_year+1,future_year+10)]\n",
    "  fls_keys = fls_key_list + future_year_terms\n",
    "  for sent in sentences:\n",
    "    sent_lower = sent.lower()\n",
    "    if is_forward_looking(sent_lower, fls_keys): \n",
    "      fl_sent = fl_sent + 1\n",
    "      if is_term(sent_lower, qt_key_list) and is_future_year(sent_lower, future_year_terms):\n",
    "        fl_qt_sent_both = fl_qt_sent_both + 1\n",
    "      elif is_term(sent_lower, qt_key_list) and (not is_future_year(sent_lower, future_year_terms)):\n",
    "        fl_qt_sent_keys = fl_qt_sent_keys + 1\n",
    "      elif (not is_term(sent_lower, qt_key_list)) and is_future_year(sent_lower, future_year_terms):\n",
    "        fl_qt_sent_year = fl_qt_sent_year + 1\n",
    "      else:\n",
    "        fl_nqt_sent = fl_nqt_sent + 1\n",
    "    else:\n",
    "      nfl_sent = nfl_sent + 1\n",
    "      if is_term(sent_lower, qt_key_list) and is_future_year(sent_lower, future_year_terms):\n",
    "        nfl_qt_sent_both = nfl_qt_sent_both + 1\n",
    "      elif is_term(sent_lower, qt_key_list) and (not is_future_year(sent_lower, future_year_terms)):\n",
    "        nfl_qt_sent_keys = nfl_qt_sent_keys + 1\n",
    "      elif (not is_term(sent_lower, qt_key_list)) and is_future_year(sent_lower, future_year_terms):\n",
    "        nfl_qt_sent_year = nfl_qt_sent_year + 1\n",
    "      else:\n",
    "        nfl_nqt_sent = nfl_nqt_sent + 1\n",
    "  \n",
    "  fl_qt_sent = fl_qt_sent_keys + fl_qt_sent_year + fl_qt_sent_both\n",
    "  nfl_qt_sent = nfl_qt_sent_keys + nfl_qt_sent_year + nfl_qt_sent_both\n",
    "  \n",
    "  fl_dict.update({\"fl_sent\": fl_sent})\n",
    "  fl_dict.update({\"fl_qt_sent\": fl_qt_sent}) \n",
    "  fl_dict.update({\"fl_qt_sent_both\": fl_qt_sent_both})   \n",
    "  fl_dict.update({\"fl_qt_sent_keys\": fl_qt_sent_keys})   \n",
    "  fl_dict.update({\"fl_qt_sent_year\": fl_qt_sent_year})   \n",
    "  fl_dict.update({\"fl_nqt_sent\": fl_nqt_sent}) \n",
    "  fl_dict.update({\"nfl_sent\": nfl_sent})\n",
    "  fl_dict.update({\"nfl_qt_sent\": nfl_qt_sent}) \n",
    "  fl_dict.update({\"nfl_qt_sent_both\": nfl_qt_sent_both})   \n",
    "  fl_dict.update({\"nfl_qt_sent_keys\": nfl_qt_sent_keys})   \n",
    "  fl_dict.update({\"nfl_qt_sent_year\": nfl_qt_sent_year})   \n",
    "  fl_dict.update({\"nfl_nqt_sent\": nfl_nqt_sent})   \n",
    "  text = the_text.lower()\n",
    "  fl_dict.update({\"word\": text_word_count(text)})\n",
    "  fl_dict.update({\"sent\": len(sentences)})\n",
    "  \n",
    "  if len(sentences) > 0 and (text_word_count(the_text)>0):\n",
    "    return fl_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4421a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_classifier(sent, fls_key_list=fls_terms_regex, qt_key_list=qt_terms_regex, future_year=2023): \n",
    "  \n",
    "  future_year = int(future_year)  \n",
    "  future_year_terms=[re.compile(r\"[^$,]\\b\" + str(y) + r\"\\b(?!(%|,\\d|.\\d))\") for y in range(future_year+1,future_year+10)]\n",
    "  fls_keys = fls_key_list + future_year_terms\n",
    "  sent_lower = sent.lower()\n",
    "  \n",
    "  fl = 0\n",
    "  qt = 0\n",
    "  \n",
    "  if is_forward_looking(sent_lower, fls_keys): \n",
    "    fl = 1\n",
    "  if is_term(sent_lower, qt_key_list) or is_future_year(sent_lower, future_year_terms):\n",
    "    qt = 1\n",
    "  \n",
    "  if text_word_count(sent)>0:\n",
    "    return fl, qt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a555bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "list2=[]\n",
    "\n",
    "for i in range(len(gold_standard.speaker_text.tolist())):\n",
    "  list1.append(sent_classifier(sent=gold_standard.speaker_text.tolist()[i], future_year=gold_standard.future_year.tolist()[i])[0])\n",
    "  list2.append(sent_classifier(sent=gold_standard.speaker_text.tolist()[i], future_year=gold_standard.future_year.tolist()[i])[1])\n",
    "\n",
    "gold_standard['fl_cal'] = list1\n",
    "gold_standard['qt_cal'] = list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4d32e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fl_qt(fl, qt):\n",
    "    return fl * qt\n",
    "\n",
    "gold_standard[\"fl_qt_cal\"] = gold_standard.apply(lambda x: fl_qt(x[\"fl_cal\"], x[\"qt_cal\"]), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19569d34",
   "metadata": {},
   "source": [
    "The following function generates statistics to report the performance of the algorithm on identifying forward-looking statements and forward-looking statements with time frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "322980da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(df, type = 'fl'):\n",
    "    var = type\n",
    "    var_cal = type + '_cal'\n",
    "    \n",
    "    tn = sum((df[var] == df[var_cal]) & ~df[var_cal])\n",
    "    fp = sum((df[var] != df[var_cal]) & df[var_cal])\n",
    "    fn = sum((df[var] != df[var_cal]) & ~df[var_cal])\n",
    "    tp = sum((df[var] == df[var_cal]) & df[var_cal])\n",
    "    \n",
    "    print(\"Accuracy {:.2f}%\".format( 100 * (tp + tn)/(tp + tn + fp + fn)))\n",
    "    if tp + fp > 0:\n",
    "        print(\"Precision {:.2f}%\".format( 100 * tp/(tp + fp)))\n",
    "    if tp + fn > 0:\n",
    "        print(\"True positive rate {:.2f}%\".format( 100 * tp/(tp + fn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a5fc9a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 95.23%\n",
      "Precision 82.09%\n",
      "True positive rate 85.94%\n"
     ]
    }
   ],
   "source": [
    "print_stats(gold_standard[gold_standard['training sample']==1], type = 'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "49d87da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 97.16%\n",
      "Precision 90.20%\n",
      "True positive rate 69.70%\n"
     ]
    }
   ],
   "source": [
    "print_stats(gold_standard[gold_standard['training sample']==1], type = 'fl_qt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8279b9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 95.82%\n",
      "Precision 83.61%\n",
      "True positive rate 87.93%\n"
     ]
    }
   ],
   "source": [
    "print_stats(gold_standard[gold_standard['training sample']==0], type = 'fl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8b09f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 96.81%\n",
      "Precision 76.00%\n",
      "True positive rate 73.08%\n"
     ]
    }
   ],
   "source": [
    "print_stats(gold_standard[gold_standard['training sample']==0], type = 'fl_qt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
